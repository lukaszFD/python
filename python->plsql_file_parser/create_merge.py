import re
import os

# --- Configuration ---
# Path on Lenovo ThinkPad X390
BASE_DIR = "/home/hunter/IdeaProjects/python/python->plsql_file_parser/examples"
SOURCE_SCHEMA = "SOURCE_SCHEMA"
TARGET_SCHEMA = "TARGET_SCHEMA"
TABLE_PREFIX = "TEST_"

# Package and Audit Configuration
PACKAGE_NAME = "PKG_SENTINEL_DATA_SYNC"
AUDIT_PKG_NAME = "PKG_AUDIT_UTILS"
JOB_INTERVAL = "FREQ=DAILY; BYHOUR=2; BYMINUTE=0" # Every day at 2:00 AM

# Output Directories
OUTPUT_PKG_DIR = os.path.join(BASE_DIR, TARGET_SCHEMA, "PKG")
OUTPUT_TABLE_DIR = os.path.join(BASE_DIR, TARGET_SCHEMA, "TABLE")
OUTPUT_JOB_DIR = os.path.join(BASE_DIR, TARGET_SCHEMA, "JOB")

def get_columns_from_file(file_path):
    """
    Extracts column names from DDL file.
    Excludes system keywords and the audit column 'INSERTED_ON'.
    """
    columns = []
    if not os.path.exists(file_path):
        return columns

    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()

    # Split by lines to find column definitions
    lines = content.split('\n')
    for line in lines:
        line = line.strip()
        # Regex to capture column name (handles optional double quotes)
        col_match = re.match(r'^"?(\w+)"?\s+\w+', line)
        if col_match:
            name = col_match.group(1).upper()
            # Exclude keywords and the auto-calculated audit column
            if name not in ["CREATE", "TABLE", "INSERTED_ON"]:
                columns.append(name)
    return columns

def generate_full_system():
    # Ensure all output directories exist
    os.makedirs(OUTPUT_PKG_DIR, exist_ok=True)
    os.makedirs(OUTPUT_TABLE_DIR, exist_ok=True)
    os.makedirs(OUTPUT_JOB_DIR, exist_ok=True)

    # 1. Generate Audit Table DDL (APP_SYNC_STATS)
    audit_table_sql = f"""CREATE TABLE "{TARGET_SCHEMA}"."APP_SYNC_STATS" 
(
    "STAT_ID" NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    "TABLE_NAME" VARCHAR2(100),
    "SYNC_DATE" DATE DEFAULT SYSDATE,
    "ROWS_PROCESSED" NUMBER,
    "STATUS" VARCHAR2(20),
    "ERROR_MESSAGE" VARCHAR2(4000)
);
"""
    with open(os.path.join(OUTPUT_TABLE_DIR, "APP_SYNC_STATS.sql"), 'w') as f:
        f.write(audit_table_sql)

    # 2. Generate Audit Package (PKG_AUDIT_UTILS)
    # Uses PRAGMA AUTONOMOUS_TRANSACTION to log even if main transaction fails
    audit_pkg_sql = f"""CREATE OR REPLACE PACKAGE "{TARGET_SCHEMA}"."{AUDIT_PKG_NAME}" AS
    PROCEDURE LOG_STATS(p_table_name IN VARCHAR2, p_rows IN NUMBER, p_status IN VARCHAR2, p_error IN VARCHAR2 DEFAULT NULL);
END "{AUDIT_PKG_NAME}";
/

CREATE OR REPLACE PACKAGE BODY "{TARGET_SCHEMA}"."{AUDIT_PKG_NAME}" AS
    PROCEDURE LOG_STATS(p_table_name IN VARCHAR2, p_rows IN NUMBER, p_status IN VARCHAR2, p_error IN VARCHAR2 DEFAULT NULL) IS
        PRAGMA AUTONOMOUS_TRANSACTION;
    BEGIN
        INSERT INTO "APP_SYNC_STATS" (TABLE_NAME, ROWS_PROCESSED, STATUS, ERROR_MESSAGE)
        VALUES (p_table_name, p_rows, p_status, p_error);
        COMMIT;
    END LOG_STATS;
END "{AUDIT_PKG_NAME}";
/"""
    with open(os.path.join(OUTPUT_PKG_DIR, f"{AUDIT_PKG_NAME}.sql"), 'w') as f:
        f.write(audit_pkg_sql)

    # 3. Process Target Tables for Merge Package and Jobs
    target_table_dir = os.path.join(BASE_DIR, TARGET_SCHEMA, "TABLE")
    procedures_spec = []
    procedures_body = []

    for filename in sorted(os.listdir(target_table_dir)):
        # Skip audit table and non-sql files
        if not filename.endswith(".sql") or "APP_SYNC_STATS" in filename:
            continue

        target_table_name = filename.replace(".sql", "").upper()
        source_table_name = target_table_name.replace(TABLE_PREFIX, "", 1)

        columns = get_columns_from_file(os.path.join(target_table_dir, filename))
        if not columns:
            continue

        proc_name = f"PRC_LOAD_{source_table_name}"
        job_name = f"JOB_{proc_name}"

        # Build MERGE logic using all extracted columns
        on_clause = " AND ".join([f"tgt.{c} = src.{c}" for c in columns])
        update_set = ",\n                ".join([f"tgt.{c} = src.{c}" for c in columns])
        cols_joined = ", ".join(columns)
        vals_joined = ", ".join([f"src.{c}" for c in columns])

        procedures_spec.append(f"    PROCEDURE {proc_name};")

        # Merge procedure with Audit integration
        body = f"""    PROCEDURE {proc_name} IS
        v_rows NUMBER;
    BEGIN
        MERGE INTO "{TARGET_SCHEMA}"."{target_table_name}" tgt
        USING "{SOURCE_SCHEMA}"."{source_table_name}" src
        ON ({on_clause})
        WHEN MATCHED THEN
            UPDATE SET 
                {update_set}
        WHEN NOT MATCHED THEN
            INSERT ({cols_joined})
            VALUES ({vals_joined});
            
        v_rows := SQL%ROWCOUNT;
        
        "{AUDIT_PKG_NAME}".LOG_STATS('{target_table_name}', v_rows, 'SUCCESS');
        COMMIT;
    EXCEPTION
        WHEN OTHERS THEN
            "{AUDIT_PKG_NAME}".LOG_STATS('{target_table_name}', 0, 'ERROR', SQLERRM);
            ROLLBACK;
            RAISE;
    END {proc_name};"""
        procedures_body.append(body)

        # 4. Generate individual Job file for this procedure
        job_sql = f"""BEGIN
    DBMS_SCHEDULER.CREATE_JOB (
        job_name        => '"{TARGET_SCHEMA}"."{job_name}"',
        job_type        => 'STORED_PROCEDURE',
        job_action      => '"{TARGET_SCHEMA}"."{PACKAGE_NAME}"."{proc_name}"',
        start_date      => SYSTIMESTAMP,
        repeat_interval => '{JOB_INTERVAL}',
        enabled         => TRUE,
        comments        => 'Daily sync for {target_table_name}'
    );
END;
/"""
        with open(os.path.join(OUTPUT_JOB_DIR, f"{job_name}.sql"), 'w') as f_job:
            f_job.write(job_sql)

    # 5. Assemble and Save the Main Package (Spec and Body)
    full_pkg_sql = f"""CREATE OR REPLACE PACKAGE "{TARGET_SCHEMA}"."{PACKAGE_NAME}" AS
{chr(10).join(procedures_spec)}
END "{PACKAGE_NAME}";
/

CREATE OR REPLACE PACKAGE BODY "{TARGET_SCHEMA}"."{PACKAGE_NAME}" AS
{chr(10).join(procedures_body)}
END "{PACKAGE_NAME}";
/"""

    with open(os.path.join(OUTPUT_PKG_DIR, f"{PACKAGE_NAME}.sql"), 'w') as f_pkg:
        f_pkg.write(full_pkg_sql)

    print("System generation complete:")
    print(f"- Audit Table: {os.path.join(OUTPUT_TABLE_DIR, 'APP_SYNC_STATS.sql')}")
    print(f"- Audit Package: {os.path.join(OUTPUT_PKG_DIR, AUDIT_PKG_NAME + '.sql')}")
    print(f"- Main Package: {os.path.join(OUTPUT_PKG_DIR, PACKAGE_NAME + '.sql')}")
    print(f"- Jobs created in: {OUTPUT_JOB_DIR}")

if __name__ == "__main__":
    generate_full_system()